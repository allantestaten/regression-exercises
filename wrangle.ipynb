{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e57c45c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from env import get_db_url\n",
    "from pathlib import Path \n",
    "import csv\n",
    "import acquire\n",
    "\n",
    "#from env import user, password, host\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124c7f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"\"\"SELECT bedroomcnt,bathroomcnt,calculatedfinishedsquarefeet, yearbuilt, taxvaluedollarcnt,taxamount,fips\n",
    "                FROM properties_2017\n",
    "                LEFT JOIN propertylandusetype as pl using (propertylandusetypeid)\n",
    "                WHERE pl.propertylandusetypeid = '261'\"\"\"\n",
    "\n",
    "df = pd.read_sql(sql_query, get_db_url('zillow'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d65b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE QUERY TO CSV\n",
    "filepath = Path('zillow.csv')\n",
    "filepath.parent.mkdir(parents=True,exist_ok=True)\n",
    "df.to_csv(filepath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099c7484",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reading dataframe from local drive\n",
    "df = pd.read_csv('zillow.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffb59e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information about table, how many nulls are in each column \n",
    "\n",
    "df.info(show_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1c9ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns that can be changed for readability\n",
    "df = df.rename(columns = {'bedroomcnt':'bedrooms', \n",
    "                          'bathroomcnt':'bathrooms', \n",
    "                          'calculatedfinishedsquarefeet':'area',\n",
    "                          'taxvaluedollarcnt':'tax_value', \n",
    "                          'yearbuilt':'year_built'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e86a0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total of null values for each row\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59158849",
   "metadata": {},
   "source": [
    "**Takeaway**\n",
    "- If our plan is to remove outliers, could removing outliers also reduce our null count?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b146ef",
   "metadata": {},
   "source": [
    "### Visualizing Distributions & Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e7844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 3))\n",
    "\n",
    "# List of columns\n",
    "cols = [col for col in df.columns if col not in ['fips', 'year_built']]\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "\n",
    "    # i starts at 0, but plot numbers should start at 1\n",
    "    plot_number = i + 1 \n",
    "\n",
    "    # Create subplot.\n",
    "    plt.subplot(1, len(cols), plot_number)\n",
    "\n",
    "    # Title with column name.\n",
    "    plt.title(col)\n",
    "\n",
    "    # Display histogram for column.\n",
    "    df[col].hist(bins=5)\n",
    "\n",
    "    # Hide gridlines.\n",
    "    plt.grid(False)\n",
    "    \n",
    "    # turn off scientific notation\n",
    "    plt.ticklabel_format(useOffset=False)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987c2bcd",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "- Outliers must exist in each column for the x-axis to have the range shown\n",
    "- `tax_value` is looking like it has severe skew, due to a x-axis range that goes to 1e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd41199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at tax_value in closer detail\n",
    "df['tax_value'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27f8600",
   "metadata": {},
   "source": [
    "### Boxplots\n",
    "Show outliers as black diamonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc62443",
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot figure created\n",
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "plt.ticklabel_format(useOffset=False, style='plain')\n",
    "sns.boxplot(data=df.drop(columns=['fips']))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a2a103",
   "metadata": {},
   "source": [
    "`tax_value` shows an extreme number of outliers making it difficult to identify outliers in other columns\n",
    "\n",
    "It may be beneficial to make this chart larger or break it out into individual box plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18199ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating boxplot for every column except fips and year built\n",
    "cols = [col for col in df.columns if col not in ['fips', 'year_built']]\n",
    "plt.figure(figsize=(16, 20))\n",
    "for i, col in enumerate(cols):\n",
    "\n",
    "    # i starts at 0, but plot numbers should start at 1\n",
    "    plot_number = i + 1 \n",
    "\n",
    "    # Create subplot\n",
    "    plt.subplot(1, len(cols), plot_number)\n",
    "\n",
    "    # Title with column name.\n",
    "    plt.title(col)\n",
    "\n",
    "    # Display boxplot for column.\n",
    "    sns.boxplot(data=df[col])\n",
    "\n",
    "    # Hide gridlines.\n",
    "    plt.grid(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d05239",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "Can see there are significant amounts of outliers in each column "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1848ad",
   "metadata": {},
   "source": [
    "What are the quartiles for each of these columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d493249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing quartiles for each column\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dbac36",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "- Substantial outliers exist\n",
    "- Depending on what model is being used to predict it may be beneficial to drop all nulls.\n",
    "- If model will predict median value of homes than dropping nulls is not an issue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e263dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, k, col_list):\n",
    "    ''' remove outliers from a list of columns in a dataframe \n",
    "        and return that dataframe\n",
    "    '''\n",
    "    \n",
    "    for col in col_list:\n",
    "        \n",
    "        # get quartiles\n",
    "        q1, q3 = df[col].quantile([.25, .75])  \n",
    "        \n",
    "        # calculate interquartile range\n",
    "        iqr = q3 - q1   \n",
    "        \n",
    "        upper_bound = q3 + k * iqr   # get upper bound\n",
    "        lower_bound = q1 - k * iqr   # get lower bound\n",
    "\n",
    "        # return dataframe without outliers\n",
    "        \n",
    "        df = df[(df[col] > lower_bound) & (df[col] < upper_bound)]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa3cd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use 1.5 for k(1.5 times interquartile for upper and lower bound, most data lies within 1,2,3 std dev of mean\n",
    "df = remove_outliers(df, 1.5, ['bedrooms', 'bathrooms', 'area', 'tax_value', 'taxamount'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f73089",
   "metadata": {},
   "source": [
    "### Revisualize Distributions\n",
    "Lets revisualize our data now that its be cleaned a bit (approximately 300,000 observations removed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34529e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 3))\n",
    "\n",
    "# List of columns\n",
    "cols = [col for col in df.columns if col not in ['fips', 'year_built']]\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "\n",
    "    # i starts at 0, but plot nos should start at 1\n",
    "    plot_number = i + 1 \n",
    "\n",
    "    # Create subplot.\n",
    "    plt.subplot(1, len(cols), plot_number)\n",
    "\n",
    "    # Title with column name.\n",
    "    plt.title(col)\n",
    "\n",
    "    # Display histogram for column.\n",
    "    df[col].hist(bins=5)\n",
    "\n",
    "    # Hide gridlines.\n",
    "    plt.grid(False)\n",
    "    \n",
    "    # turn off scientific notation\n",
    "    plt.ticklabel_format(useOffset=False)\n",
    "    \n",
    "    # mitigate overlap\n",
    "    plt.tight_layout()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c63191",
   "metadata": {},
   "source": [
    "## Takeaways \n",
    "* Bedrooms and bathrooms are not normally distributed\n",
    "* Other fields are not normal and are skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4913087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns\n",
    "cols = ['bedrooms', 'bathrooms', 'area', 'tax_value', 'taxamount']\n",
    "\n",
    "plt.figure(figsize=(16, 3))\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "\n",
    "    # i starts at 0, but plot should start at 1\n",
    "    plot_number = i + 1 \n",
    "\n",
    "    # Create subplot.\n",
    "    plt.subplot(1, len(cols), plot_number)\n",
    "\n",
    "    # Title with column name.\n",
    "    plt.title(col)\n",
    "\n",
    "    # Display boxplot for column.\n",
    "    sns.boxplot(data=df[[col]])\n",
    "\n",
    "    # Hide gridlines.\n",
    "    plt.grid(False)\n",
    "\n",
    "    # sets proper spacing between plots\n",
    "    plt.tight_layout()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535a7e06",
   "metadata": {},
   "source": [
    "## Takeaways \n",
    "* Still a few outliers despite the relatively restrictive 1.5 * IQR setting for the upper/lower boundary\n",
    "* No need to remove these outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a6e76c",
   "metadata": {},
   "source": [
    "### How do the null values look now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9996b3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total of null values for each row\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a2c7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider imputing year ()built\n",
    "df.year_built.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79fbb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#glance at the data\n",
    "#df.year_built.describe()\n",
    "\n",
    "#formats data to be more readable/ multiplies all data by 10**3\n",
    "df.year_built.describe().apply(lambda x: format(x, 'f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ba3629",
   "metadata": {},
   "source": [
    "* The null values have been cleaned up by removing the outliers\n",
    "* The mean, median, and mode are all relatively similar to each other\n",
    "* We could try and develop a complex imputation method to estimate the year built based off other columns, but for speed, we will just use the median."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aae896",
   "metadata": {},
   "source": [
    "### If removing the outliers does not clean up nulls? What can be done? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b592dc",
   "metadata": {},
   "source": [
    "`.dropna()`\n",
    "We can utilize some of the parameters of .dropna() to clean up our nulls:\n",
    "\n",
    "- axis: {0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "    - 0, or ‘index’ : Drop rows which contain missing values.\n",
    "    - 1, or ‘columns’ : Drop columns which contain missing value.\n",
    "- how: {‘any’, ‘all’}, default ‘any’\n",
    "    - ‘any’ : If any NA values are present, drop that row or column.\n",
    "    - ‘all’ : If all values are NA, drop that row or column.\n",
    "- thresh: int, optional\n",
    "    - Require that many non-NA values.\n",
    "- subset: array-like, optional\n",
    "    - Give the columns to consider, ignore non-listed columns\n",
    "\n",
    "Thresh is useful, but it is limited to an integer amount. What if we wanted to remove columns that had a certain proportion of na values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95e2cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set our null threshold. Any columns that have this ratio or higher will be removed\n",
    "missing_perc_thresh = 0.98\n",
    "\n",
    "# Create empty list to keep track of which columns we plan on dropping\n",
    "exclude_missing = []\n",
    "\n",
    "# Find columns that have a greater null percentage than our threshold\n",
    "num_rows = df.shape[0]\n",
    "for c in df.columns:\n",
    "    num_missing = df[c].isnull().sum()\n",
    "    if num_missing == 0:\n",
    "        continue\n",
    "    missing_frac = num_missing / float(num_rows)\n",
    "    if missing_frac > missing_perc_thresh:\n",
    "        exclude_missing.append(c)\n",
    "print(\"We exclude: %s\" % exclude_missing)\n",
    "\n",
    "# Drop these columns from our dataset\n",
    "df.drop(columns=exclude_missing, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819eb8bf",
   "metadata": {},
   "source": [
    "### Are the column data types correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf467e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905c4c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get value counts and decide on data types\n",
    "cols = df.columns\n",
    "\n",
    "for col in cols:\n",
    "    \n",
    "    print(col.upper())\n",
    "    print(df[col].value_counts())\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06e398e",
   "metadata": {},
   "source": [
    "* casting fips and year built as an object because it is a numerical represintation of a catagorical value\n",
    "* leaving the rest as floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b376161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fips = df.fips.astype(object)\n",
    "df.year_built = df.year_built.astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ac64e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2be21ae",
   "metadata": {},
   "source": [
    "## Target Leakage\n",
    "\n",
    "Consider the goal of the model to be developed:\n",
    "\n",
    "        Build an end-to-end project in which you use some of their Kaggle data to predict property values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ab0598",
   "metadata": {},
   "source": [
    "`taxamount` is determined by a real estate tax appraisers valuation of the home combined with the local tax rate.\n",
    "\n",
    "The question to consider, does this represent information that we wouldn't have at the time of prediction? Does this represent the target variable? This is where specific domain knowledge is very important.\n",
    "\n",
    "Tax appraised values often deviate from the sale price of a property due to a number of reasons:\n",
    "- Unlike market value, homeowners are incentivized to reduce their tax value appraisal. As a result, some homeowners may misrepresent the features/size of their property to avoid a bigger tax bill\n",
    "- Some counties limit the tax appraisal increase to a set amount, causing tax appraised value to significantly lag behind home values in hot markets\n",
    "- Local tax appraisers evaluate homes based on evaluation criteria that can differ from county to county or even year to year based on political and administrative pressures\n",
    "\n",
    "This data is a snapshot of home information in 2017. There is an additional column in the database containing assessment year. This might be useful to know the recency of any given taxamount value. \n",
    "\n",
    "When a home is being appraised to evaluate for market pricing, prior years home value is not considered in that price determination. That doesn't mean that prior years home value is not predictive of price. It could be. For this reason, we will allow `taxamount` to remain in the dataset. \n",
    "\n",
    "Without this specific domain knowledge, this column seems to represent the risk of target leak. If you are in a situation where you don't know if you have a target leak situation, its probably generally better to err on the side of caution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8bd607",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5bc210",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validate, test = train_test_split(df, test_size=.2, random_state=123)\n",
    "train, validate = train_test_split(train_validate, test_size=.3, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c2333f",
   "metadata": {},
   "source": [
    "## Impute year_built with mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bacf13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputing year_built with mode of median for year built \n",
    "imputer = SimpleImputer(strategy='median')  # build imputer\n",
    "\n",
    "imputer.fit(train[['year_built']]) # fit to train\n",
    "\n",
    "# transform the data\n",
    "train[['year_built']] = imputer.transform(train[['year_built']])\n",
    "validate[['year_built']] = imputer.transform(validate[['year_built']])\n",
    "test[['year_built']] = imputer.transform(test[['year_built']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19de1393",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efd83d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a3e44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8559a655",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb7291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f71c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf22e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Wrangles data from Zillow Database'''\n",
    "\n",
    "##################################################Wrangle.py###################################################\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from env import user, password, host\n",
    "\n",
    "#**************************************************Acquire*******************************************************\n",
    "\n",
    "def acquire_zillow():\n",
    "    ''' Acquire data from Zillow using env imports and rename columns'''\n",
    "    \n",
    "    url = f\"mysql+pymysql://{user}:{password}@{host}/zillow\"\n",
    "    \n",
    "    query = \"\"\"\n",
    "            \n",
    "    SELECT bedroomcnt, bathroomcnt, calculatedfinishedsquarefeet, taxvaluedollarcnt, yearbuilt, taxamount, fips\n",
    "    FROM properties_2017\n",
    "\n",
    "    LEFT JOIN propertylandusetype USING(propertylandusetypeid)\n",
    "\n",
    "    WHERE propertylandusedesc IN (\"Single Family Residential\",                       \n",
    "                                  \"Inferred Single Family Residential\")\"\"\"\n",
    "\n",
    "    # get dataframe of data\n",
    "    df = pd.read_sql(query, url)\n",
    "    \n",
    "    \n",
    "    # renaming column names to one's I like better\n",
    "    df = df.rename(columns = {'bedroomcnt':'bedrooms', \n",
    "                              'bathroomcnt':'bathrooms', \n",
    "                              'calculatedfinishedsquarefeet':'area',\n",
    "                              'taxvaluedollarcnt':'tax_value', \n",
    "                              'yearbuilt':'year_built',})\n",
    "    return df\n",
    "\n",
    "#**************************************************Remove Outliers*******************************************************\n",
    "\n",
    "def remove_outliers(df, k, col_list):\n",
    "    ''' remove outliers from a list of columns in a dataframe \n",
    "        and return that dataframe\n",
    "    '''\n",
    "    \n",
    "    for col in col_list:\n",
    "\n",
    "        q1, q3 = df[col].quantile([.25, .75])  # get quartiles\n",
    "        \n",
    "        iqr = q3 - q1   # calculate interquartile range\n",
    "        \n",
    "        upper_bound = q3 + k * iqr   # get upper bound\n",
    "        lower_bound = q1 - k * iqr   # get lower bound\n",
    "\n",
    "        # return dataframe without outliers\n",
    "        \n",
    "        df = df[(df[col] > lower_bound) & (df[col] < upper_bound)]\n",
    "        \n",
    "    return df\n",
    "\n",
    "#**************************************************Distributions*******************************************************\n",
    "\n",
    "def get_hist(df):\n",
    "    ''' Gets histographs of acquired continuous variables'''\n",
    "    \n",
    "    plt.figure(figsize=(16, 3))\n",
    "\n",
    "    # List of columns\n",
    "    cols = [col for col in df.columns if col not in ['fips', 'year_built']]\n",
    "\n",
    "    for i, col in enumerate(cols):\n",
    "\n",
    "        # i starts at 0, but plot nos should start at 1\n",
    "        plot_number = i + 1 \n",
    "\n",
    "        # Create subplot.\n",
    "        plt.subplot(1, len(cols), plot_number)\n",
    "\n",
    "        # Title with column name.\n",
    "        plt.title(col)\n",
    "\n",
    "        # Display histogram for column.\n",
    "        df[col].hist(bins=5)\n",
    "\n",
    "        # Hide gridlines.\n",
    "        plt.grid(False)\n",
    "\n",
    "        # turn off scientific notation\n",
    "        plt.ticklabel_format(useOffset=False)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "        \n",
    "        \n",
    "def get_box(df):\n",
    "    ''' Gets boxplots of acquired continuous variables'''\n",
    "    \n",
    "    # List of columns\n",
    "    cols = ['bedrooms', 'bathrooms', 'area', 'tax_value', 'taxamount']\n",
    "\n",
    "    plt.figure(figsize=(16, 3))\n",
    "\n",
    "    for i, col in enumerate(cols):\n",
    "\n",
    "        # i starts at 0, but plot should start at 1\n",
    "        plot_number = i + 1 \n",
    "\n",
    "        # Create subplot.\n",
    "        plt.subplot(1, len(cols), plot_number)\n",
    "\n",
    "        # Title with column name.\n",
    "        plt.title(col)\n",
    "\n",
    "        # Display boxplot for column.\n",
    "        sns.boxplot(data=df[[col]])\n",
    "\n",
    "        # Hide gridlines.\n",
    "        plt.grid(False)\n",
    "\n",
    "        # sets proper spacing between plots\n",
    "        plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "        \n",
    "#**************************************************Prepare*******************************************************\n",
    "\n",
    "def prepare_zillow(df):\n",
    "    ''' Prepare zillow data for exploration'''\n",
    "\n",
    "    # removing outliers\n",
    "    df = remove_outliers(df, 1.5, ['bedrooms', 'bathrooms', 'area', 'tax_value', 'taxamount'])\n",
    "    \n",
    "    # get distributions of numeric data\n",
    "    get_hist(df)\n",
    "    get_box(df)\n",
    "    \n",
    "    # converting column datatypes\n",
    "    df.fips = df.fips.astype(object)\n",
    "    df.year_built = df.year_built.astype(object)\n",
    "    \n",
    "    # train/validate/test split\n",
    "    train_validate, test = train_test_split(df, test_size=.2, random_state=123)\n",
    "    train, validate = train_test_split(train_validate, test_size=.3, random_state=123)\n",
    "    \n",
    "    # impute year built using mode\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "    imputer.fit(train[['year_built']])\n",
    "\n",
    "    train[['year_built']] = imputer.transform(train[['year_built']])\n",
    "    validate[['year_built']] = imputer.transform(validate[['year_built']])\n",
    "    test[['year_built']] = imputer.transform(test[['year_built']])       \n",
    "    \n",
    "    return train, validate, test    \n",
    "\n",
    "\n",
    "#**************************************************Wrangle*******************************************************\n",
    "\n",
    "\n",
    "def wrangle_zillow():\n",
    "    '''Acquire and prepare data from Zillow database for explore'''\n",
    "    train, validate, test = prepare_zillow(acquire_zillow())\n",
    "    \n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093decc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = wrangle_zillow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de0a1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe597799",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"zillow.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87e07c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedroomcnt</th>\n",
       "      <th>bathroomcnt</th>\n",
       "      <th>calculatedfinishedsquarefeet</th>\n",
       "      <th>yearbuilt</th>\n",
       "      <th>taxvaluedollarcnt</th>\n",
       "      <th>taxamount</th>\n",
       "      <th>fips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27516.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6037.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6037.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6037.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2108.0</td>\n",
       "      <td>174.21</td>\n",
       "      <td>6037.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3633.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>296425.0</td>\n",
       "      <td>6941.39</td>\n",
       "      <td>6037.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152858</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2262.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>960756.0</td>\n",
       "      <td>13494.52</td>\n",
       "      <td>6059.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152859</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3127.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>536061.0</td>\n",
       "      <td>6244.16</td>\n",
       "      <td>6059.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152860</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>208057.0</td>\n",
       "      <td>5783.88</td>\n",
       "      <td>6059.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152861</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>424353.0</td>\n",
       "      <td>5302.70</td>\n",
       "      <td>6059.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152862</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2110.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>554009.0</td>\n",
       "      <td>6761.20</td>\n",
       "      <td>6037.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2152863 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         bedroomcnt  bathroomcnt  calculatedfinishedsquarefeet  yearbuilt  \\\n",
       "0               0.0          0.0                           NaN        NaN   \n",
       "1               0.0          0.0                           NaN        NaN   \n",
       "2               0.0          0.0                           NaN        NaN   \n",
       "3               0.0          0.0                           NaN        NaN   \n",
       "4               4.0          2.0                        3633.0     2005.0   \n",
       "...             ...          ...                           ...        ...   \n",
       "2152858         4.0          3.0                        2262.0     2015.0   \n",
       "2152859         4.0          4.5                        3127.0     2014.0   \n",
       "2152860         0.0          0.0                           NaN        NaN   \n",
       "2152861         3.0          2.5                        1974.0     2015.0   \n",
       "2152862         4.0          4.0                        2110.0     2014.0   \n",
       "\n",
       "         taxvaluedollarcnt  taxamount    fips  \n",
       "0                  27516.0        NaN  6037.0  \n",
       "1                     10.0        NaN  6037.0  \n",
       "2                     10.0        NaN  6037.0  \n",
       "3                   2108.0     174.21  6037.0  \n",
       "4                 296425.0    6941.39  6037.0  \n",
       "...                    ...        ...     ...  \n",
       "2152858           960756.0   13494.52  6059.0  \n",
       "2152859           536061.0    6244.16  6059.0  \n",
       "2152860           208057.0    5783.88  6059.0  \n",
       "2152861           424353.0    5302.70  6059.0  \n",
       "2152862           554009.0    6761.20  6037.0  \n",
       "\n",
       "[2152863 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acquire.get_zillow_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207682fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
